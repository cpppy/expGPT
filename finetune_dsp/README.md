

TODO:
1. cache token_ids for dataset
2. bfloat16 training
3. optimizer to AdamW
4. quantum training with lora
5. wandb
6. recovery from checkpoint(optimizer state)
7. lr_scheduler
8. 